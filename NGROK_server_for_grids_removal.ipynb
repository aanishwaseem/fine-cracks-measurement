{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5KZpHk-4GPO",
        "outputId": "c0724768-3f25-4c23-b40a-48c12b738865",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: typer 0.21.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "google-adk 1.21.0 requires fastapi<0.124.0,>=0.115.0, but you have fastapi 0.108.0 which is incompatible.\n",
            "google-adk 1.21.0 requires starlette<1.0.0,>=0.49.1, but you have starlette 0.32.0.post1 which is incompatible.\n",
            "google-adk 1.21.0 requires websockets<16.0.0,>=15.0.1, but you have websockets 11.0.3 which is incompatible.\n",
            "dataproc-spark-connect 1.0.1 requires websockets>=14.0, but you have websockets 11.0.3 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "yfinance 0.2.66 requires websockets>=13.0, but you have websockets 11.0.3 which is incompatible.\n",
            "pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-genai 1.55.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\n",
            "sse-starlette 3.1.2 requires starlette>=0.49.1, but you have starlette 0.32.0.post1 which is incompatible.\n",
            "python-fasthtml 0.12.39 requires starlette>0.33, but you have starlette 0.32.0.post1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "iopaint 1.6.0 requires Pillow==9.5.0, but you have pillow 12.1.0 which is incompatible.\n",
            "gradio 4.21.0 requires numpy~=1.0, but you have numpy 2.3.5 which is incompatible.\n",
            "gradio 4.21.0 requires pillow<11.0,>=8.0, but you have pillow 12.1.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "cudf-cu12 25.10.0 requires numba<0.62.0a0,>=0.60.0, but you have numba 0.63.1 which is incompatible.\n",
            "yfinance 0.2.66 requires websockets>=13.0, but you have websockets 11.0.3 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "cuml-cu12 25.10.0 requires numba<0.62.0a0,>=0.60.0, but you have numba 0.63.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRemember, installing models for the first time will be very slow! Be patient.\n",
            "IOPaint public URL: NgrokTunnel: \"https://unfunereal-unconvertibly-tresa.ngrok-free.dev\" -> \"http://localhost:8000\"\n",
            "Please wait until the \"Application startup complete.\" message appears...\n",
            ">>> starting iopaint start --model lama --device cuda --port 8000 --interactive-seg-device cuda --interactive-seg-model sam_hq_vit_b --remove-bg-model briaai/RMBG-1.4 --realesrgan-model realesr-general-x4v3 --realesrgan-device cuda --gfpgan-device cuda --restoreformer-device cuda\n",
            "2026-01-27 04:35:33.154 | INFO     | iopaint.runtime:setup_model_dir:81 - Model directory: /root/.cache\n",
            "- Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "- Python version: 3.12.12\n",
            "- torch: 2.9.0+cu126\n",
            "- torchvision: 0.24.0+cu126\n",
            "- Pillow: 12.1.0\n",
            "- diffusers: 0.27.2\n",
            "- transformers: 4.48.3\n",
            "- opencv-python: 4.11.0.86\n",
            "- accelerate: 1.12.0\n",
            "- iopaint: 1.6.0\n",
            "- rembg: 2.0.72\n",
            "- onnxruntime: 1.23.2\n",
            "\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769488545.325152    1235 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769488545.332219    1235 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769488545.347611    1235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769488545.347632    1235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769488545.347635    1235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769488545.347638    1235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.12/dist-packages/iopaint/model/ldm.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "@torch.cuda.amp.autocast()\n",
            "2026-01-27 04:35:49.843 | INFO     | iopaint.cli:start:183 - lama not found in /root/.cache, try to downloading\n",
            "2026-01-27 04:35:49.843 | INFO     | iopaint.download:cli_download_model:27 - Downloading lama...\n",
            "Downloading: \"https://github.com/Sanster/models/releases/download/add_big_lama/big-lama.pt\" to /root/.cache/torch/hub/checkpoints/big-lama.pt\n",
            "100%|██████████| 196M/196M [00:05<00:00, 40.5MB/s]\n",
            "2026-01-27 04:35:55.618 | INFO     | iopaint.helper:download_model:57 - Download model success, md5: e3aa4aaa15225a33ec84f9f4bc47e500\n",
            "2026-01-27 04:35:55.618 | INFO     | iopaint.download:cli_download_model:29 - Done.\n",
            "[W127 04:35:55.710818099 init.cpp:772] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())\n",
            "2026-01-27 04:35:55.953 | INFO     | iopaint.model_manager:init_model:47 - Loading model: lama\n",
            "2026-01-27 04:35:55.954 | INFO     | iopaint.helper:load_jit_model:107 - Loading model from: /root/.cache/torch/hub/checkpoints/big-lama.pt\n",
            "INFO:     Started server process [1235]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
            "2026-01-27 04:42:15.571 | INFO     | iopaint.api:api_inpaint:274 - image ext: png\n",
            "2026-01-27 04:42:15.572 | INFO     | iopaint.model.base:__call__:97 - Run crop strategy\n",
            "2026-01-27 04:42:17.366 | INFO     | iopaint.api:api_inpaint:285 - process time: 1793.56ms\n",
            "{\n",
            "\"host\": \"127.0.0.1\",\n",
            "\"port\": 8000,\n",
            "\"inbrowser\": false,\n",
            "\"model\": \"lama\",\n",
            "\"no_half\": false,\n",
            "\"low_mem\": false,\n",
            "\"cpu_offload\": false,\n",
            "\"disable_nsfw_checker\": false,\n",
            "\"local_files_only\": false,\n",
            "\"cpu_textencoder\": false,\n",
            "\"device\": \"cuda\",\n",
            "\"input\": null,\n",
            "\"mask_dir\": null,\n",
            "\"output_dir\": null,\n",
            "\"quality\": 100,\n",
            "\"enable_interactive_seg\": false,\n",
            "\"interactive_seg_model\": \"sam_hq_vit_b\",\n",
            "\"interactive_seg_device\": \"cuda\",\n",
            "\"enable_remove_bg\": false,\n",
            "\"remove_bg_device\": \"cpu\",\n",
            "\"remove_bg_model\": \"briaai/RMBG-1.4\",\n",
            "\"enable_anime_seg\": false,\n",
            "\"enable_realesrgan\": false,\n",
            "\"realesrgan_device\": \"cuda\",\n",
            "\"realesrgan_model\": \"realesr-general-x4v3\",\n",
            "\"enable_gfpgan\": false,\n",
            "\"gfpgan_device\": \"cuda\",\n",
            "\"enable_restoreformer\": false,\n",
            "\"restoreformer_device\": \"cuda\"\n",
            "}\n",
            "INFO:     103.198.155.15:0 - \"POST /api/v1/inpaint HTTP/1.1\" 200 OK\n",
            "2026-01-27 04:54:37.841 | INFO     | iopaint.api:api_inpaint:274 - image ext: png\n",
            "2026-01-27 04:54:37.842 | INFO     | iopaint.model.base:__call__:97 - Run crop strategy\n",
            "2026-01-27 04:54:38.141 | INFO     | iopaint.api:api_inpaint:285 - process time: 299.72ms\n",
            "INFO:     103.198.155.15:0 - \"POST /api/v1/inpaint HTTP/1.1\" 200 OK\n",
            "2026-01-27 05:02:00.197 | INFO     | iopaint.api:api_inpaint:274 - image ext: png\n",
            "2026-01-27 05:02:00.197 | INFO     | iopaint.model.base:__call__:97 - Run crop strategy\n",
            "2026-01-27 05:02:00.487 | INFO     | iopaint.api:api_inpaint:285 - process time: 290.62ms\n",
            "INFO:     103.198.155.15:0 - \"POST /api/v1/inpaint HTTP/1.1\" 200 OK\n",
            "2026-01-27 05:03:54.099 | INFO     | iopaint.api:api_inpaint:274 - image ext: png\n",
            "2026-01-27 05:03:54.099 | INFO     | iopaint.model.base:__call__:97 - Run crop strategy\n",
            "2026-01-27 05:03:54.399 | INFO     | iopaint.api:api_inpaint:285 - process time: 299.86ms\n",
            "INFO:     103.198.155.15:0 - \"POST /api/v1/inpaint HTTP/1.1\" 200 OK\n",
            "2026-01-27 05:04:37.420 | INFO     | iopaint.api:api_inpaint:274 - image ext: png\n",
            "2026-01-27 05:04:37.420 | INFO     | iopaint.model.base:__call__:97 - Run crop strategy\n",
            "2026-01-27 05:04:37.816 | INFO     | iopaint.api:api_inpaint:285 - process time: 395.56ms\n",
            "INFO:     103.198.155.15:0 - \"POST /api/v1/inpaint HTTP/1.1\" 200 OK\n",
            "2026-01-27 05:09:13.016 | INFO     | iopaint.api:api_inpaint:274 - image ext: png\n",
            "2026-01-27 05:09:13.017 | INFO     | iopaint.model.base:__call__:97 - Run crop strategy\n",
            "2026-01-27 05:09:13.431 | INFO     | iopaint.api:api_inpaint:285 - process time: 414.41ms\n",
            "INFO:     103.198.155.15:0 - \"POST /api/v1/inpaint HTTP/1.1\" 200 OK\n",
            "2026-01-27 05:10:12.558 | INFO     | iopaint.api:api_inpaint:274 - image ext: png\n",
            "2026-01-27 05:10:12.559 | INFO     | iopaint.model.base:__call__:97 - Run crop strategy\n",
            "2026-01-27 05:10:12.885 | INFO     | iopaint.api:api_inpaint:285 - process time: 325.86ms\n",
            "INFO:     103.151.42.15:0 - \"POST /api/v1/inpaint HTTP/1.1\" 200 OK\n",
            "2026-01-27 05:15:07.006 | INFO     | iopaint.api:api_inpaint:274 - image ext: png\n",
            "2026-01-27 05:15:07.007 | INFO     | iopaint.model.base:__call__:97 - Run crop strategy\n",
            "2026-01-27 05:15:07.340 | INFO     | iopaint.api:api_inpaint:285 - process time: 333.78ms\n",
            "INFO:     103.151.42.15:0 - \"POST /api/v1/inpaint HTTP/1.1\" 200 OK\n",
            "2026-01-27 05:18:57.182 | INFO     | iopaint.api:api_inpaint:274 - image ext: png\n",
            "2026-01-27 05:18:57.182 | INFO     | iopaint.model.base:__call__:97 - Run crop strategy\n",
            "2026-01-27 05:18:57.493 | INFO     | iopaint.api:api_inpaint:285 - process time: 311.18ms\n",
            "INFO:     103.151.42.15:0 - \"POST /api/v1/inpaint HTTP/1.1\" 200 OK\n",
            "2026-01-27 05:23:09.925 | INFO     | iopaint.api:api_inpaint:274 - image ext: png\n",
            "2026-01-27 05:23:09.926 | INFO     | iopaint.model.base:__call__:97 - Run crop strategy\n",
            "2026-01-27 05:23:10.228 | INFO     | iopaint.api:api_inpaint:285 - process time: 302.03ms\n",
            "INFO:     103.151.42.15:0 - \"POST /api/v1/inpaint HTTP/1.1\" 200 OK\n",
            "2026-01-27 05:34:58.790 | INFO     | iopaint.api:api_inpaint:274 - image ext: png\n",
            "2026-01-27 05:34:58.791 | INFO     | iopaint.model.base:__call__:97 - Run crop strategy\n",
            "2026-01-27 05:34:59.108 | INFO     | iopaint.api:api_inpaint:285 - process time: 317.64ms\n",
            "INFO:     103.151.42.15:0 - \"POST /api/v1/inpaint HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "#@markdown In order to use this colab:\n",
        "#@markdown - Enter your [ngrok auth token](https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "#@markdown - Select a model ([find documentation here](https://www.iopaint.com/models))\n",
        "#@markdown - Select the T4 GPU accelerator at `Runtime > Change runtime type > Hardware accelerator`\n",
        "#@markdown - Click `Runtime > Run all`\n",
        "#@markdown - Follow the link to access the UI\n",
        "\n",
        "#@markdown Note: beware that installing models for the first time will take some time.\n",
        "ngrok_token = \"38fjGAnDayMyp7mduDzsseI3fqC_2eV2vSJ9WsqYxTKnoPjzM\"\n",
        "model = \"lama\" # @param [\"lama\", \"mat\", \"migan\", \"runwayml/stable-diffusion-inpainting\", \"Sanster/PowerPaint-V1-stable-diffusion-inpainting\", \"Uminosachi/realisticVisionV51_v51VAE-inpainting\", \"Sanster/anything-4.0-inpainting\", \"redstonehero/dreamshaper-inpainting\", \"Sanster/AnyText\", \"timbrooks/instruct-pix2pix\", \"Fantasy-Studio/Paint-by-Example\"]\n",
        "enable_interactive_seg = False # @param {type: \"boolean\"}\n",
        "interactive_seg_device = \"cuda\" # @param [\"cuda\", \"cpu\"]\n",
        "interactive_seg_model = \"sam_hq_vit_b\" # @param [\"sam_hq_vit_b\", \"sam_hq_vit_l\", \"sam_hq_vit_h\"]\n",
        "enable_remove_bg = False # @param {type: \"boolean\"}\n",
        "remove_bg_model = \"briaai/RMBG-1.4\" # @param [\"u2net\", \"u2netp\", \"u2net_human_seg\", \"u2net_cloth_seg\", \"silueta\", \"isnet-general-use\", \"briaai/RMBG-1.4\"]\n",
        "enable_realesrgan = False # @param {type: \"boolean\"}\n",
        "realesrgan_model = \"realesr-general-x4v3\" # @param [\"realesr-general-x4v3\", \"RealESRGAN_x4plus\", \"RealESRGAN_x4plus_anime_6B\"]\n",
        "realesrgan_device = \"cuda\" # @param [\"cuda\", \"cpu\"]\n",
        "enable_gfpgan = False # @param {type: \"boolean\"}\n",
        "gfpgan_device = \"cuda\" # @param [\"cuda\", \"cpu\"]\n",
        "enable_restoreformer = False # @param {type: \"boolean\"}\n",
        "restoreformer_device = \"cuda\" # @param [\"cuda\", \"cpu\"]\n",
        "\n",
        "# Download and install iopaint and pyngrok\n",
        "!pip install iopaint pyngrok > install_logs.txt\n",
        "!iopaint install-plugins-packages > plugins_install_logs.txt\n",
        "\n",
        "import os\n",
        "import asyncio\n",
        "from pyngrok import ngrok\n",
        "import sys\n",
        "\n",
        "os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})\n",
        "\n",
        "print(\"Remember, installing models for the first time will be very slow! Be patient.\")\n",
        "\n",
        "async def run_process(cmd):\n",
        "  print('>>> starting', *cmd)\n",
        "  p = await asyncio.subprocess.create_subprocess_exec(\n",
        "      *cmd,\n",
        "      stdout=asyncio.subprocess.PIPE,\n",
        "      stderr=asyncio.subprocess.PIPE,\n",
        "  )\n",
        "\n",
        "  async def pipe(lines):\n",
        "    async for line in lines:\n",
        "      print(line.strip().decode('utf-8'))\n",
        "\n",
        "  await asyncio.gather(\n",
        "      pipe(p.stdout),\n",
        "      pipe(p.stderr),\n",
        "  )\n",
        "\n",
        "if not ngrok_token:\n",
        "  print(\"Hey! You haven't set the Ngrok token. Without the token, the app won't start. Please paste your token in the input.\")\n",
        "  sys.exit(\"Ngrok token not set\")\n",
        "\n",
        "ngrok.set_auth_token(ngrok_token)\n",
        "active_tunnels = ngrok.get_tunnels()\n",
        "for tunnel in active_tunnels:\n",
        "    public_url = tunnel.public_url\n",
        "    ngrok.disconnect(public_url)\n",
        "url = ngrok.connect(addr=\"8000\", bind_tls=True)\n",
        "print(f\" public URL: {url}\")\n",
        "print(\"Please wait until the \\\"Application startup complete.\\\" message appears...\")\n",
        "\n",
        "cmds = [\n",
        "    'iopaint', 'start', '--model', model, '--device', 'cuda', '--port', '8000',\n",
        "    '--interactive-seg-device', interactive_seg_device,\n",
        "    '--interactive-seg-model', interactive_seg_model,\n",
        "    '--remove-bg-model', remove_bg_model,\n",
        "    '--realesrgan-model', realesrgan_model,\n",
        "    '--realesrgan-device', realesrgan_device,\n",
        "    '--gfpgan-device', gfpgan_device,\n",
        "    '--restoreformer-device', restoreformer_device\n",
        "]\n",
        "\n",
        "if enable_interactive_seg:\n",
        "  cmds.append('--enable-interactive-seg')\n",
        "if enable_remove_bg:\n",
        "  cmds.append('--enable-remove-bg')\n",
        "if enable_realesrgan:\n",
        "  cmds.append('--enable-realesrgan')\n",
        "if enable_gfpgan:\n",
        "  cmds.append('--enable-gfpgan')\n",
        "if enable_restoreformer:\n",
        "  cmds.append('--enable-restoreformer')\n",
        "\n",
        "await asyncio.gather(\n",
        "    run_process(cmds)\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}